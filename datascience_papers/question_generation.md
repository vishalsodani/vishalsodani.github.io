- Automatic Factual Question Generation from Text
    - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.208.5602&rep=rep1&type=pdf
    - **This research supports the idea that natural language processing can help teachers efficiently create
instructional content. It provides solutions to some of the major challenges in question generation
and an analysis and better understanding of those that remain**.
    - Thesis Statement
        - Automatic factual question generation can be effectively modeled using an overgeneration and statistical ranking approach
    - 16 categories of questions
        - http://www.cs.memphis.edu/~vrus/questiongeneration/16-GraesserEtAl-QG08.pdf
        - This paper aims to generate two types of questions: 
            - concept completion questions (  elicit a particular information
that completes a given partial concept )
            - verification questions ( yes or no )
        - Cognitive Focus - "The questions generated by this work mainly assess recognition and recall of information—and, to a much lesser extent, comprehension."
        - The discuss educational value of factual questions
            - shallow vs deep questions
            - talk about various studies
        - QG Approaches
            - Mitkov and Ha - 

        - Cloze Procedure
            - To generate a cloze test, one takes a passage and **replaces some of the words in the passage with blanks**
            - an online tool - https://lextutor.ca/cgi-bin/cloze/n/
            - Another paper on cloze 
                - https://pdfs.semanticscholar.org/8272/3e32350234be0c078a97b8b1d32fd6594141.pdf
                    - Automatic Generation System of Multiple-Choice Cloze
Questions and its Evaluation
                - Generating distractors is also an important issue in the automatic generation of
multiple-choice cloze questions
                    - https://link.springer.com/chapter/10.1007/978-3-642-14770-8_5 - distractor generation technique


        - **TECHNIQUE**
            - “overgenerate-and-rank”
                The system generates a large set of candidate questions using existing NLP tools and manually
written rules. It then ranks candidate questions using a statistical model of question quality

            - QG technique based on "Extracting Simplified Statements for Factual Question Generation"
                - http://www.cs.cmu.edu/~./mheilman/papers/heilman-smith-qg-extr-facts.pdf



Tools Mentioned
    Stanford Parser - https://nlp.stanford.edu/software/lex-parser.html

    POS to tag words as noun, verbs etc and Chunking to get phrases
    https://medium.com/greyatom/learning-pos-tagging-chunking-in-nlp-85f7f811a8cb

    Alphabetical list of part-of-speech tags used in the Penn Treebank Project
    https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html

    Information EXtraction
    https://web.stanford.edu/class/cs124/lec/Information_Extraction_and_Named_Entity_Recognition.pdf